#!/usr/bin/env python
# Downloads images from Gelbooru

import asyncio
import getpass
import os
import re
import xml.dom.minidom
from contextlib import contextmanager
from typing import List, Dict, Generator
import configargparse
import requests
from dotfiles import logging


def sanitize_file_name(name: str) -> str:
    return re.sub(r'[\\\/:*?"<>|]', '_', name)


class DownloadHistory:
    def __init__(self, path: str) -> None:
        self.path = path
        self.downloaded_urls: Dict[str, bool] = {}
        self.buffered_urls: List[str] = []
        if os.path.exists(path):
            for line in open(path, 'r'):
                self.downloaded_urls[line.strip()] = True

    def add(self, url: str) -> None:
        if self.is_downloaded(url):
            return
        self.downloaded_urls[url] = True
        self.buffered_urls.append(url)

    def flush(self) -> None:
        os.makedirs(os.path.dirname(self.path), exist_ok=True)
        with open(self.path, 'a') as handle:
            for url in self.buffered_urls:
                print(url, file=handle)
        self.buffered_urls = []

    def is_downloaded(self, url: str) -> bool:
        return url in self.downloaded_urls


class DownloadStats:
    def __init__(self) -> None:
        self.errors = 0
        self.ignored = 0
        self.downloaded = 0

    def ignore(self, url: str, reason: str) -> None:
        logging.info('%s... %s', url, reason)
        self.ignored += 1

    @contextmanager
    def download(self, url: str) -> Generator:
        try:
            logging.info('%s... downloading', url)
            yield
            self.downloaded += 1
            logging.info('%s... ok', url)
        except Exception as ex:
            logging.error('error: %s', ex)
            self.errors += 1


class Downloader:
    def __init__(
            self,
            base_dir: str,
            history: DownloadHistory,
            force: bool) -> None:
        self.base_dir = base_dir
        self.history = history
        self.force = force
        self.limit = 10
        self.stats = DownloadStats()
        self.session = requests.session()

    def login(self, user: str, password: str) -> None:
        response = self.session.post(
            'http://gelbooru.com/index.php?page=account&s=login&code=00',
            data={
                'user': user,
                'pass': password,
                'submit': 'Log in',
            })
        response.raise_for_status()

    def get_target_path(self, post_id: int, url: str) -> str:
        return os.path.join(
            self.base_dir,
            'gelbooru_' + str(post_id) + '_' + os.path.basename(url))

    def download_file(self, url: str, post_id: int) -> None:
        target_path = self.get_target_path(post_id, url)
        if not url.startswith('http'):
            url = 'http://' + url.lstrip('/')

        if os.path.exists(target_path):
            self.stats.ignore(url, 'already exists')
            return

        if not self.force \
                and self.history.is_downloaded(os.path.basename(url)):
            self.stats.ignore(url, 'already downloaded')
            return

        response = None
        attempt = 0
        while True:
            attempt += 1
            with self.stats.download(url):
                try:
                    response = self.session.get(url)
                    response.raise_for_status()
                    break
                except Exception:
                    if attempt > 3:
                        raise
        assert response

        with open(target_path, 'wb') as handle:
            handle.write(response.content)
        self.history.add(os.path.basename(url))
        self.history.flush()

    def download_page(self, page: int, query: str) -> bytes:
        url = (
            'http://gelbooru.com/index.php?page=dapi&s=post&q=index'
            + '&limit=' + str(self.limit)
            + '&tags=' + query
            + '&pid=' + str(page))
        response = self.session.get(url)
        response.raise_for_status()
        return response.content

    def run(self, query: str) -> None:
        page = 0
        while True:
            response = self.download_page(page, query)
            with xml.dom.minidom.parseString(response) as doc:
                posts = doc.getElementsByTagName('post')
                if not posts:
                    break
                loop = asyncio.get_event_loop()
                loop.run_until_complete(asyncio.gather(*[
                    loop.run_in_executor(
                        None,
                        self.download_file,
                        post.getAttribute('file_url'),
                        int(post.getAttribute('id')))
                    for post in posts]))
                page += 1
        logging.info('Downloaded: %d', self.stats.downloaded)
        logging.info('Ignored: %d', self.stats.ignored)
        logging.info('Errors: %d', self.stats.errors)


def parse_args() -> configargparse.Namespace:
    parser = configargparse.ArgParser(
        'Download images from gelbooru.',
        default_config_files=['~/.config/dl-gelbooru.conf'])
    parser.add('query', nargs='+')
    parser.add('-u', '--user')
    parser.add('-p', '--password')
    parser.add('--cache-path', default='~/.cache/dl-pixiv.log')
    parser.add('--target-dir', default='~')
    parser.add('-f', '--force', action='store_true')
    return parser.parse_args()


def main() -> None:
    args = parse_args()
    user_name: str = args.user or input('User:')
    password: str = args.password or getpass.getpass('Password:')
    query: str = ' '.join(args.query)
    target_dir: str = args.target_dir
    cache_path: str = os.path.expanduser(args.cache_path)
    force: bool = args.force

    target_dir = os.path.expanduser(
        os.path.join(target_dir, sanitize_file_name(query)))
    os.makedirs(target_dir, exist_ok=True)

    history = DownloadHistory(cache_path)
    downloader = Downloader(target_dir, history, force)
    downloader.login(user_name, password)
    downloader.run(query)


if __name__ == '__main__':
    main()
