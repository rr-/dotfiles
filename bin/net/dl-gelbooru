#!/usr/bin/env python
# Downloads images from Gelbooru

import asyncio
import argparse
import os
import re
import xml.dom.minidom
from contextlib import contextmanager
from typing import List, Dict, Generator
import requests
from dotfiles import config
from dotfiles import logging

CONFIG_KEY = 'ul-gelbooru'
USER_NAME = config[CONFIG_KEY]['user']
PASSWORD = config[CONFIG_KEY]['password']
LOG_PATH = os.path.expanduser('~/.cache/gelbooru.log')


class UrlList:
    def __init__(self) -> None:
        self.downloaded_urls: Dict[str, bool] = {}
        self.buffered_urls: List[str] = []
        if os.path.exists(LOG_PATH):
            for line in open(LOG_PATH, 'r'):
                self.downloaded_urls[line.strip()] = True

    def add(self, url: str) -> None:
        if self.is_downloaded(url):
            return
        self.downloaded_urls[url] = True
        self.buffered_urls.append(url)

    def flush(self) -> None:
        os.makedirs(os.path.dirname(LOG_PATH), exist_ok=True)
        with open(LOG_PATH, 'a') as handle:
            for url in self.buffered_urls:
                print(url, file=handle)
        self.buffered_urls = []

    def is_downloaded(self, url: str) -> bool:
        return url in self.downloaded_urls


class DownloadStats:
    def __init__(self) -> None:
        self.errors = 0
        self.ignored = 0
        self.downloaded = 0

    def ignore(self, url: str, reason: str) -> None:
        logging.info('%s... %s', url, reason)
        self.ignored += 1

    @contextmanager
    def download(self, url: str) -> Generator:
        try:
            logging.info('%s... downloading', url)
            yield
            self.downloaded += 1
            logging.info('ok')
        except Exception as ex:
            logging.error('error: %s', ex)
            self.errors += 1


class Downloader:
    def __init__(self, base_dir: str, url_list: UrlList, force: bool) -> None:
        self.base_dir = base_dir
        self.url_list = url_list
        self.force = force
        self.limit = 10
        self.stats = DownloadStats()
        self.session = requests.session()

    def login(self, user: str, password: str) -> None:
        response = self.session.post(
            'http://gelbooru.com/index.php?page=account&s=login&code=00',
            data={
                'user': user,
                'pass': password,
                'submit': 'Log in',
            })
        response.raise_for_status()

    def get_target_path(self, post_id: int, url: str) -> str:
        return os.path.join(
            self.base_dir,
            'gelbooru_' + str(post_id) + '_' + os.path.basename(url))

    def download_file(self, url: str, post_id: int) -> None:
        target_path = self.get_target_path(post_id, url)
        if not url.startswith('http'):
            url = 'http://' + url.lstrip('/')

        if not self.force \
                and self.url_list.is_downloaded(os.path.basename(url)):
            self.stats.ignore(url, 'already downloaded')
            return

        if os.path.exists(target_path):
            self.stats.ignore(url, 'already exists')
            return

        with self.stats.download(url):
            response = self.session.get(url)
            response.raise_for_status()
            with open(target_path, 'wb') as handle:
                handle.write(response.content)
            self.url_list.add(os.path.basename(url))
            self.url_list.flush()

    def download_page(self, page: int, query: str) -> bytes:
        url = (
            'http://gelbooru.com/index.php?page=dapi&s=post&q=index'
            + '&limit=' + str(self.limit)
            + '&tags=' + query
            + '&pid=' + str(page))
        response = self.session.get(url)
        response.raise_for_status()
        return response.content

    def run(self, query: str) -> None:
        page = 0
        while True:
            response = self.download_page(page, query)
            with xml.dom.minidom.parseString(response) as doc:
                posts = doc.getElementsByTagName('post')
                if not posts:
                    break
                loop = asyncio.get_event_loop()
                loop.run_until_complete(asyncio.gather(*[
                    loop.run_in_executor(
                        None,
                        self.download_file,
                        post.getAttribute('file_url'),
                        int(post.getAttribute('id')))
                    for post in posts]))
                page += 1
        logging.info('Downloaded: %d', self.stats.downloaded)
        logging.info('Ignored: %d', self.stats.ignored)
        logging.info('Errors: %d', self.stats.errors)


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser('Download images from gelbooru.')
    parser.add_argument('query', nargs='+')
    parser.add_argument('--target-dir', default='~/img/net/gelbooru/')
    parser.add_argument('-f', '--force', action='store_true')
    return parser.parse_args()


def sanitize_filename(name: str) -> str:
    return re.sub(r'[\\\/:*?"<>|]', '_', name)


def main() -> None:
    args = parse_args()
    query: str = ' '.join(args.query)
    target_dir: str = args.target_dir
    force: bool = args.force

    target_dir = os.path.expanduser(target_dir + sanitize_filename(query))
    os.makedirs(target_dir, exist_ok=True)

    url_list = UrlList()
    downloader = Downloader(target_dir, url_list, force)
    downloader.login(USER_NAME, PASSWORD)
    downloader.run(query)


if __name__ == '__main__':
    main()
