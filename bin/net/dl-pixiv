#!/usr/bin/env python
# Downloads images from Pixiv

import asyncio
import getpass
import json
import os
import re
from concurrent.futures import ThreadPoolExecutor
from contextlib import contextmanager
from typing import Optional, List, Dict, Generator
import configargparse
import requests
from dotfiles import logging


PAGE_SIZE = 10
MAX_CONCURRENT_DOWNLOADS = 5
MAX_ATTEMPTS = 3


def sanitize_file_name(name):
    return re.sub(r'[\\/*?:"<>|]', '_', name)


class DownloadHistory:
    def __init__(self, path: str) -> None:
        self.path = path
        self.downloaded_urls: Dict[str, bool] = {}
        self.buffered_urls: List[str] = []
        if os.path.exists(path):
            for line in open(path, 'r'):
                self.downloaded_urls[line.strip()] = True

    def add(self, url: str) -> None:
        if self.is_downloaded(url):
            return
        self.downloaded_urls[url] = True
        self.buffered_urls.append(url)

    def flush(self) -> None:
        os.makedirs(os.path.dirname(self.path), exist_ok=True)
        with open(self.path, 'a') as handle:
            for url in self.buffered_urls:
                print(url, file=handle)
        self.buffered_urls = []

    def is_downloaded(self, url: str) -> bool:
        return url in self.downloaded_urls


class DownloadStats:
    def __init__(self) -> None:
        self.errors = 0
        self.ignored = 0
        self.downloaded = 0

    def ignore(self, url: str, reason: str) -> None:
        logging.info('%s... %s', url, reason)
        self.ignored += 1

    @contextmanager
    def download(self, url: str) -> Generator:
        try:
            logging.info('%s... downloading', url)
            yield
            self.downloaded += 1
            logging.info('%s... ok', url)
        except Exception as ex:
            logging.error('error: %s', ex)
            self.errors += 1
            raise


class Downloader:
    def __init__(
            self,
            base_dir: str,
            history: DownloadHistory,
            force: bool) -> None:
        self.base_dir = base_dir
        self.history = history
        self.force = force
        self.stats = DownloadStats()
        self.session = requests.session()

    def login(self, user_name: str, password: str) -> None:
        url = 'https://oauth.secure.pixiv.net/auth/token'
        data = {
            'username': user_name,
            'password': password,
            'grant_type': 'password',
            'client_id': 'bYGKuGVw91e0NMfPGp44euvGt59s',
            'client_secret': 'HP3RmkgAmEGro0gn1x9ioawQE8WMfvLXDz3ZqxpK',
        }
        response = self.session.post(url, data=data)
        response.raise_for_status()
        response_data = self._parse_response(response.text)
        access_token = response_data['response']['access_token']
        self.session.headers.update({
            # 'User-Agent': 'PixivIOSApp/6.4.0',
            'Referer': 'http://www.pixiv.net/',
            'Authorization': 'Bearer {}'.format(access_token)})

    def run_artist(self, artist_id: int, limit: int) -> None:
        def get_page(page, page_size):
            return self._get_artist_page(artist_id, page, page_size)

        def get_dir_name(item):
            return '{} - {}'.format(artist_id, item['user']['name'])

        self._run(get_page, get_dir_name, limit)

    def run_query(self, query: str, limit: int) -> None:
        def get_page(page, page_size):
            return self._get_query_page(query, page, page_size)

        def get_dir_name(_item):
            return sanitize_file_name(query)

        self._run(get_page, get_dir_name, limit)

    def _run(self, page_getter, dir_name_getter, limit: int) -> None:
        done = 0
        page = 1
        page_size = PAGE_SIZE

        loop = asyncio.get_event_loop()
        executor = ThreadPoolExecutor(max_workers=MAX_CONCURRENT_DOWNLOADS)
        while page is not None and (not limit or done < limit):
            page_data = page_getter(page, page_size)

            tasks = []
            for item in page_data['response']:
                url = item['image_urls']['large']
                path = self._get_target_path(
                    dir_name_getter(item), item['title'], url)
                tasks.append(
                    loop.run_in_executor(
                        executor, self._download, url, path))
            results = loop.run_until_complete(asyncio.gather(*tasks))
            done += sum(int(result) for result in results)

            page_size = min(page_size, len(page_data['response']))
            page = page_data['pagination']['next']

        logging.info('Downloaded: %d', self.stats.downloaded)
        logging.info('Ignored: %d', self.stats.ignored)
        logging.info('Errors: %d', self.stats.errors)

    def _get_artist_page(
            self, artist_id: int, page: int, page_size: int) -> Dict:
        url = (
            'https://public-api.secure.pixiv.net/v1/users/{}/works.json'
            .format(artist_id))
        params = {
            'page': page,
            'per_page': page_size,
            'include_stats': True,
            'include_sanity_level': True,
            'image_sizes': ','.join(
                ['px_128x128', 'px_480mw', 'small', 'medium', 'large']),
            'profile_image_sizes': ','.join(['px_170x170', 'px_50x50']),
        }
        response = self.session.get(url, params=params)
        return self._parse_response(response.text)

    def _get_query_page(
            self, query: str, page: int, page_size: int) -> Dict:
        url = 'https://public-api.secure.pixiv.net/v1/search/works.json'
        params = {
            'q': query,
            'page': page,
            'per_page': page_size,
            'include_stats': True,
            'include_sanity_level': True,
            'image_sizes': ','.join(
                ['px_128x128', 'px_480mw', 'small', 'medium', 'large']),
            'profile_image_sizes': ','.join(['px_170x170', 'px_50x50']),
        }
        response = self.session.get(url, params=params)
        return self._parse_response(response.text)

    def _download(self, url: str, target_path: str) -> bool:
        if os.path.exists(target_path):
            self.stats.ignore(url, 'already exists')
            return False

        if not self.force \
                and self.history.is_downloaded(os.path.basename(url)):
            self.stats.ignore(url, 'already downloaded')
            return False

        response = None
        attempt = 0
        while True:
            attempt += 1
            with self.stats.download(url):
                try:
                    response = self.session.get(url)
                    response.raise_for_status()
                    break
                except Exception:
                    if attempt > MAX_ATTEMPTS:
                        raise
        assert response

        target_dir = os.path.dirname(target_path)
        os.makedirs(target_dir, exist_ok=True)
        with open(target_path, 'wb') as handle:
            handle.write(response.content)
        self.history.add(os.path.basename(url))
        self.history.flush()
        return True

    def _get_target_path(
            self, dir_name: str, illust_title: str, url: str) -> str:
        stem, ext = os.path.splitext(os.path.basename(url))
        name = (
            '{} - {}{}'.format(stem, illust_title, ext)
            if illust_title
            else '{}{}'.format(stem, ext))
        name = sanitize_file_name(name)
        return os.path.join(self.base_dir, dir_name, name)

    def _parse_response(self, text: str) -> Dict:
        ret = json.loads(text)
        if 'status' not in ret or ret['status'] == 'success':
            return ret
        raise RuntimeError('Error from Pixiv: {}'.format(ret))


def parse_args() -> configargparse.Namespace:
    parser = configargparse.ArgParser(
        'Download images from pixiv.',
        default_config_files=['~/.config/dl-pixiv.conf'])
    group = parser.add_mutually_exclusive_group(required=True)
    group.add('-a', '--artist-id', type=int)
    group.add('-q', '--query', nargs='*')
    parser.add('-u', '--user')
    parser.add('-p', '--password')
    parser.add('-f', '--force', action='store_true')
    parser.add('-l', '--limit', default=0, type=int)
    parser.add('--cache-path', default='~/.cache/dl-pixiv.log')
    parser.add('--target-dir', default='~')
    return parser.parse_args()


def main() -> None:
    args = parse_args()
    user_name: str = args.user or input('User: ')
    password: str = args.password or getpass.getpass('Password: ')
    artist_id: Optional[int] = args.artist_id
    query: Optional[List[str]] = args.query
    force: bool = args.force
    cache_path: str = os.path.expanduser(args.cache_path)
    target_dir: str = os.path.expanduser(args.target_dir)
    limit: int = args.limit

    history = DownloadHistory(cache_path)
    downloader = Downloader(target_dir, history, force)
    downloader.login(user_name, password)
    if artist_id:
        downloader.run_artist(artist_id, limit)
    elif query:
        downloader.run_query(' '.join(query), limit)
    else:
        assert False


if __name__ == '__main__':
    main()
