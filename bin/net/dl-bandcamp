#!/usr/bin/env python3
import argparse
import os
import pathlib
import shelve
import sys
import tempfile
import urllib.parse
import zlib

import dateutil.parser
import demjson
import lxml.html
import regex
import requests
import tqdm
import xdg

BUFFER_SIZE = 32 * 1024
SHELVE_PATH = pathlib.Path(xdg.XDG_CACHE_HOME) / "dl-bandcamp.dat"


def download_file(source_url, target_path, desc):
    if target_path.exists():
        print(f'{desc}: "{target_path}" already exists, skipping')
        return

    response = requests.get(source_url, stream=True)
    total_size = int(response.headers.get("content-length", 0))
    target_path.parent.mkdir(exist_ok=True, parents=True)

    with tempfile.NamedTemporaryFile(
        dir=target_path.parent
    ) as handle, tqdm.tqdm(
        desc=desc, total=total_size, unit="B", unit_scale=True
    ) as pbar:
        for chunk in response.iter_content(BUFFER_SIZE):
            handle.write(chunk)
            pbar.update(len(chunk))
        os.link(handle.name, target_path)


def download_page(url, use_cache=True):
    with shelve.open(str(SHELVE_PATH)) as cache:
        if use_cache and url in cache:
            return zlib.decompress(cache[url]).decode()
        response = requests.get(url)
        response.raise_for_status()
        ret = response.text
        cache[url] = zlib.compress(ret.encode())
        return ret


def uniq(seq):
    seen = set()
    seen_add = seen.add
    return [x for x in seq if not (x in seen or seen_add(x))]


def parse_args():
    parser = argparse.ArgumentParser()
    parser.add_argument("url")
    parser.add_argument("--directory", default=".", type=pathlib.Path)
    return parser.parse_args()


def is_artist_page(url):
    return len(get_artist_album_links(url)) > 0


def is_album_page(url):
    return "/album/" in url or "/track" in url


def safe_file_name(text: str) -> str:
    return text.replace("/", "Â·")


def download_album(album_url, target_directory):
    print("Downloading album", album_url)
    response_text = download_page(album_url)
    document = lxml.html.fromstring(response_text)
    album_cover_url = document.xpath('//link[@rel="image_src"]/@href')[0]

    json_code = regex.search(
        r"(?:TralbumData = )(\{(?>[^}{]*(?1)?)*\})",
        response_text,
        flags=regex.M,
    ).group(1)
    json_code = json_code.replace('" + "', "")

    data = demjson.decode(json_code)

    album_artist = data["artist"]
    album_title = data["current"]["title"]
    album_release_date = dateutil.parser.parse(
        data.get("album_release_date")
        or data["current"].get("release_date")
        or data["current"].get("publish_date")
    )

    album_directory = target_directory / safe_file_name(
        f"{album_artist} - {album_release_date:%Y-%m-%d} - {album_title}"
    )

    download_file(album_cover_url, album_directory / "cover.jpg", desc="cover")

    for i, track_data in enumerate(data["trackinfo"]):
        track_title = track_data["title"]
        track_number = int(track_data.get("track_num") or "1")

        if track_data["file"] is None:
            print(f'Track "{track_number:02d}. {track_title}" is unavailable')
            continue
        track_url = track_data["file"]["mp3-128"]

        track_path = album_directory / safe_file_name(
            f"{track_number:02d}. {track_title}.mp3"
        )
        download_file(
            track_url,
            track_path,
            desc=f'{i + 1:02d}/{len(data["trackinfo"]):02d}',
        )


def get_album_track_links(album_url):
    response_text = download_page(album_url)
    document = lxml.html.fromstring(response_text)
    document.make_links_absolute(base_url=album_url)
    return uniq(
        [
            urllib.parse.splitquery(link)[0]
            for link in document.xpath("//a/@href")
            if "/track/" in link
        ]
    )


def get_artist_album_links(artist_url):
    response_text = download_page(artist_url, use_cache=False)
    document = lxml.html.fromstring(response_text)
    document.make_links_absolute(base_url=artist_url)
    return [
        link
        for link in document.xpath("//a/@href")
        if "/album/" in link or "/track/" in link
    ]


def main():
    args = parse_args()
    args.directory = args.directory.expanduser()
    if is_album_page(args.url):
        download_album(args.url, args.directory)
    elif is_artist_page(args.url):
        for album_link in get_artist_album_links(args.url):
            try:
                download_album(album_link, args.directory)
            except Exception as ex:
                print(ex, file=sys.stderr)
                continue
    else:
        raise RuntimeError("Neither an artist nor an album page")


if __name__ == "__main__":
    try:
        main()
        exit(0)
    except RuntimeError as ex:
        print(ex)
        exit(1)
