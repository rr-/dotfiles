#!/usr/bin/python3
# Pulls tags to yume.pl from other boorus

import os
import sys
import re
import json
import argparse
import functools
import requests
from bs4 import BeautifulSoup
from dotfiles import iqdb
from dotfiles import config
from dotfiles import logging
from dotfiles.tag_list import TagList

logger = logging.getLogger(__name__)
config_key = config['yume-autotagger']

HISTORY_PATH = os.path.expanduser('~/.config/yume-autotagger.json')
YUME_URL = config_key.get('url', 'https://yume.pl')
API_URL = config_key.get('api-url', 'https://yume.pl/api')
YUME_USER_NAME = config_key['user']
YUME_PASSWORD = config_key['password']


def sanitize_tag(name):
    return re.sub(r'\s+', '_', name)


def capitalize(name):
    return re.sub(r'(^|[_()])([a-z])', lambda m: m.group(0).upper(), name)


class SzurubooruApiError(RuntimeError):
    pass


class Tag():
    def __init__(self, name, category=None):
        self.name = name
        self.category = category

    def __str__(self):
        return self.name

    def __repr__(self):
        return 'Tag(%r, %r)' % (self.name, self.category)


def get_tags_from_gelbooru(url):
    if 'gelbooru' not in url:
        raise ValueError('Not a valid Gelbooru URL')
    session = requests.Session()
    response = session.get(url)
    soup = BeautifulSoup(response.text, 'html.parser')
    list_items = soup.select('#tag-sidebar li')
    for list_item in list_items:
        try:
            category = list_item['class'][0].replace('tag-type-', '')
            name = list_item.select('a')[1].text.replace(' ', '_')
            yield Tag(name, category)
        except IndexError:
            pass


def get_tags_from_danbooru(url):
    match = re.search(r'danbooru.*?(\d+)', url)
    if not match:
        raise ValueError('Not a valid Danbooru URL')
    post_id = int(match.group(1))
    session = requests.Session()
    response = session.get('http://danbooru.donmai.us/posts/%s.json' % post_id)
    post = json.loads(response.text)
    for category in ['artist', 'character', 'copyright', 'general']:
        for name in post['tag_string_' + category].split(' '):
            if name:
                yield Tag(name, category)


def parse_args():
    parser = argparse.ArgumentParser(
        description='Pulls tags from Gelbooru to Szurubooru')
    parser.add_argument(
        metavar='POST_ID', dest='post_ids', nargs='*', type=int,
        help=(
            'ID of the post to edit the tags for. ' +
            'If not specified, use latest unprocessed post'))
    parser.add_argument(
        '--force', action='store_true',
        help='Pull tags for already processed posts (used with POST_ID)')
    parser.add_argument(
        '--untagged', action='store_true',
        help=(
            'Pull tags only for posts that were not yet ' +
            'tagged (used with POST_ID)'))
    parser.add_argument('--source', help='Source URL where to get tags from.')
    return parser.parse_args()


def collect_third_party_tags_via_urls(source_urls):
    handlers = [
        get_tags_from_danbooru,
        get_tags_from_gelbooru,
    ]

    for handler in handlers:
        for source_url in source_urls:
            try:
                return list(handler(source_url))
            except (ValueError, NotImplementedError):
                pass

    raise iqdb.IqdbError('Post found on IQDB, but not on any known site')


def collect_third_party_tags_via_iqdb(post_url):
    source_urls = [
        result.url
        for result in iqdb.search(post_url)
        if result.similarity >= 0.90]
    return collect_third_party_tags_via_urls(source_urls)


def create_session():
    session = requests.Session()
    session.keep_alive = False
    session.auth = requests.auth.HTTPBasicAuth(YUME_USER_NAME, YUME_PASSWORD)
    session.headers['Content-Type'] = 'application/json'
    session.headers['Accept'] = 'application/json'
    response = session.get(
        API_URL + '/user/' + YUME_USER_NAME + '?bump-login')
    if response.status_code != 200:
        logger.error(json.loads(response.text)['description'])
        return None
    return session


def get_szurubooru_post(session, post_id):
    response = session.get(API_URL + '/post/' + str(post_id))
    if response.status_code != 200:
        raise SzurubooruApiError(json.loads(response.text)['description'])
    return json.loads(response.text)


def update_szurubooru_post(session, post_id, data):
    response = session.put(
        API_URL + '/post/' + str(post_id), data=json.dumps(data))
    if response.status_code != 200:
        raise SzurubooruApiError(json.loads(response.text)['description'])
    return json.loads(response.text)


@functools.lru_cache()
def get_szurubooru_tag(session, tag_name):
    response = session.get(API_URL + '/tag/' + tag_name)
    if response.status_code != 200:
        raise SzurubooruApiError(json.loads(response.text)['description'])
    return json.loads(response.text)


def create_szurubooru_tag(session, data):
    response = session.post(
        API_URL + '/tags', data=json.dumps(data))
    if response.status_code != 200:
        raise SzurubooruApiError(json.loads(response.text)['description'])
    return json.loads(response.text)


def is_banned(tag_name):
    if tag_name in config_key.get('banned', []):
        return True
    for banned_regex in config_key.get('banned_regex', []):
        if re.match(banned_regex, tag_name, re.I):
            return True
    return False


def filter_third_party_tags(third_party_tags):
    for tag in third_party_tags:
        if is_banned(tag.name):
            logger.warning('Ignored tag %r', tag.name)
            continue

        if tag.name in config_key.get('translations', {}):
            logger.info(
                'Translated tag %r → %r',
                tag.name,
                config_key['translations'][tag.name])
            tag.name = config_key['translations'][tag.name]

        sanitized_name = sanitize_tag(tag.name)
        if sanitized_name != tag.name:
            logger.info('Sanitized tag %r → %r', tag.name, sanitized_name)
            tag.name = sanitized_name

        yield tag


def collect_szurubooru_tag_implications(session, tag_name):
    try:
        upstream_tag = get_szurubooru_tag(session, tag_name)
        for implication in upstream_tag['implications']:
            yield Tag(implication)
    except SzurubooruApiError as ex:
        return []


def sync_tags(session, post_id, source=None):
    post = get_szurubooru_post(session, post_id)
    logger.info('%s/post/%d', YUME_URL, post['id'])
    logger.info(post['contentUrl'])

    new_tags = TagList()
    target_tags = TagList()
    existing_tags = TagList()
    for item in post['tags']:
        tag = Tag(item)
        target_tags.add(tag)
        existing_tags.add(tag)

    if source:
        third_party_tags = collect_third_party_tags_via_urls([source])
    else:
        try:
            third_party_tags = collect_third_party_tags_via_iqdb(
                post['contentUrl'])
        except iqdb.UploadTooBigIqdbError:
            third_party_tags = collect_third_party_tags_iqdb(
                post['thumbnailUrl'])

    for third_party_tag in filter_third_party_tags(third_party_tags):
        if third_party_tag in target_tags:
            continue

        target_tags.add(third_party_tag)

        try:
            upstream_tag = get_szurubooru_tag(session, third_party_tag.name)
            logger.info('Added existing tag %r', third_party_tag.name)
        except SzurubooruApiError as ex:
            if 'not found' in str(ex).lower():
                logger.warning('Added new tag %r', third_party_tag.name)
                new_tags.add(third_party_tag)
            else:
                raise

        for implication in collect_szurubooru_tag_implications(
                session, third_party_tag.name):
            if not implication in target_tags:
                target_tags.add(implication)
                logger.info('Added implication %r', implication.name)

    num_tags_added = len(target_tags) - len(existing_tags)
    if num_tags_added <= 0:
        logger.success('No new tags.')
        return

    if 'tagme' in target_tags:
        logger.info('Deleting tag %r', 'tagme')
        target_tags.delete('tagme')

    for new_tag in new_tags:
        logger.info('Creating new tag: %r', new_tag.name)
        if new_tag.category in ('artist', 'copyright', 'character'):
            new_tag.name = capitalize(new_tag.name)
        create_szurubooru_tag(session, {
            'names': [new_tag.name],
            'category': config_key['categories'][new_tag.category],
        })

    logger.info('Updating post tags')
    update_szurubooru_post(session, post_id, {
        'tags': [tag.name for tag in target_tags],
        'version': post['version'],
    })
    logger.success('Tagged with %d tags.', num_tags_added)


class TaggingHistory():
    def __init__(self):
        self._history = {'tagged': set(), 'untagged': set(), 'unknown': set()}
        self._load()

    def mark_as_tagged(self, post_id):
        self._history['tagged'].add(post_id)
        self._save()

    def mark_as_untagged(self, post_id):
        self._history['untagged'].add(post_id)
        self._save()

    def get_processed_post_ids(self):
        return self._history['tagged'] \
            | self._history['untagged'] \
            | self._history.get('unknown', set())

    def get_tagged_post_ids(self):
        return self._history['tagged']

    def get_untagged_post_ids(self):
        return self._history['untagged']

    def _load(self):
        if os.path.exists(HISTORY_PATH):
            with open(HISTORY_PATH, 'r') as handle:
                result = json.load(handle)
                self._history = {}
                for key in ['tagged', 'untagged', 'unknown']:
                    self._history[key] = set(result.get(key, []))

    def _save(self):
        result = {}
        for key in ['tagged', 'untagged', 'unknown']:
            result[key] = sorted(list(self._history[key]))
        with open(HISTORY_PATH, 'w') as handle:
            json.dump(result, handle)


def get_last_post_id(session, history):
    response = session.get(API_URL + '/posts?fields=id')
    decoded_response = json.loads(response.text)
    latest_id = decoded_response['results'][0]['id']
    processed_post_ids = history.get_processed_post_ids()
    for post_id in range(1, latest_id + 1):
        if post_id not in processed_post_ids:
            return post_id
    return None


def main():
    args = parse_args()
    session = create_session()
    if not session:
        logger.error('Failed to log in')
        return
    history = TaggingHistory()

    post_ids = []
    if args.post_ids:
        post_ids = args.post_ids
    else:
        last_post_id = get_last_post_id(session, history)
        if not last_post_id:
            logger.success('All posts up to date')
            return
        post_ids = [last_post_id]

    all_succeeded = True
    processed_post_ids = list(history.get_processed_post_ids())
    tagged_post_ids = list(history.get_tagged_post_ids())
    for post_id in post_ids:
        should_process = \
            post_id not in processed_post_ids \
            or args.force \
            or (post_id not in tagged_post_ids and args.untagged)

        if not should_process:
            logger.info('Skipping post %d - already processed', post_id)
            continue

        logger.info('Getting post %d...', post_id)
        try:
            sync_tags(session, post_id, args.source)
            history.mark_as_tagged(post_id)
        except ConnectionError as ex:
            logger.error(str(ex))
            all_succeded = False
        except Exception as ex:
            logger.error(str(ex))
            all_succeded = False
            history.mark_as_untagged(post_id)

    sys.exit(0 if all_succeeded else 1)


if __name__ == '__main__':
    main()
