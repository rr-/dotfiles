#!/usr/bin/python3
# Pulls tags to yume.pl from other boorus

import os
import sys
import re
import json
import argparse
import functools
import requests
from bs4 import BeautifulSoup
from dotfiles import iqdb
from dotfiles import config
from dotfiles import logging
from dotfiles.tag_list import TagList

config_key = config['yume-autotagger']

HISTORY_PATH = os.path.expanduser('~/.config/yume-autotagger.json')
YUME_URL = config_key.get('url', 'https://yume.pl')
API_URL = config_key.get('api-url', 'https://yume.pl/api')
YUME_USER_NAME = config_key['user']
YUME_PASSWORD = config_key['password']


def sanitize_tag(name):
    return re.sub(r'\s+', '_', name)


def capitalize(name):
    return re.sub(r'(^|[_()])([a-z])', lambda m: m.group(0).upper(), name)


class SzurubooruApiError(RuntimeError):
    pass


class Tag:
    def __init__(self, name, category=None):
        self.name = name
        self.category = category

    def __str__(self):
        return self.name

    def __repr__(self):
        return 'Tag(%r, %r)' % (self.name, self.category)


def get_tags_from_gelbooru(url):
    if 'gelbooru' not in url:
        raise ValueError('Not a valid Gelbooru URL')
    session = requests.Session()
    response = session.get(url)
    soup = BeautifulSoup(response.text, 'html.parser')
    list_items = soup.select('#tag-sidebar li')
    for list_item in list_items:
        try:
            category = list_item['class'][0].replace('tag-type-', '')
            name = list_item.select('a')[1].text.replace(' ', '_')
            yield Tag(name, category)
        except IndexError:
            pass


def get_tags_from_danbooru(url):
    match = re.search(r'danbooru.*?(\d+)', url)
    if not match:
        raise ValueError('Not a valid Danbooru URL')
    post_id = int(match.group(1))
    session = requests.Session()
    response = session.get('http://danbooru.donmai.us/posts/%s.json' % post_id)
    post = json.loads(response.text)
    for category in ['artist', 'character', 'copyright', 'general']:
        for name in post['tag_string_' + category].split(' '):
            if name:
                yield Tag(name, category)


def get_third_party_tags_via_urls(source_urls):
    handlers = [
        get_tags_from_danbooru,
        get_tags_from_gelbooru,
    ]

    for handler in handlers:
        for source_url in source_urls:
            try:
                return list(handler(source_url))
            except (ValueError, NotImplementedError):
                pass

    raise iqdb.IqdbError('Post found on IQDB, but not on any known site')


def get_third_party_tags_via_iqdb(post_url):
    source_urls = [
        result.url
        for result in iqdb.search(post_url)
        if result.similarity >= 0.90]
    return get_third_party_tags_via_urls(source_urls)


class SzurubooruApi:
    def __init__(self):
        self._session = requests.Session()
        self._session.keep_alive = False
        self._session.auth = (
            requests.auth.HTTPBasicAuth(YUME_USER_NAME, YUME_PASSWORD))
        self._session.headers['Content-Type'] = 'application/json'
        self._session.headers['Accept'] = 'application/json'
        self._login()

    def get_post(self, post_id):
        response = self._session.get(API_URL + '/post/' + str(post_id))
        if response.status_code != 200:
            raise SzurubooruApiError(json.loads(response.text)['description'])
        return json.loads(response.text)

    def get_last_post_id(self):
        response = self._session.get(API_URL + '/posts?fields=id')
        decoded_response = json.loads(response.text)
        return decoded_response['results'][0]['id']

    def update_post(self, post_id, data):
        response = self._session.put(
            API_URL + '/post/' + str(post_id), data=json.dumps(data))
        if response.status_code != 200:
            raise SzurubooruApiError(json.loads(response.text)['description'])
        return json.loads(response.text)

    @functools.lru_cache()
    def get_tag(self, tag_name):
        response = self._session.get(API_URL + '/tag/' + tag_name)
        if response.status_code != 200:
            raise SzurubooruApiError(json.loads(response.text)['description'])
        return json.loads(response.text)

    def create_tag(self, data):
        response = self._session.post(
            API_URL + '/tags', data=json.dumps(data))
        if response.status_code != 200:
            raise SzurubooruApiError(json.loads(response.text)['description'])
        return json.loads(response.text)

    def collect_tag_implications(self, tag_name):
        try:
            upstream_tag = self.get_tag(tag_name)
            for implication in upstream_tag['implications']:
                yield Tag(implication)
        except SzurubooruApiError:
            return []

    def _login(self):
        response = self._session.get(
            API_URL + '/user/' + YUME_USER_NAME + '?bump-login')
        if response.status_code != 200:
            raise SzurubooruApiError(json.loads(response.text)['description'])


def is_banned(tag_name):
    if tag_name in config_key.get('banned', []):
        return True
    for banned_regex in config_key.get('banned_regex', []):
        if re.match(banned_regex, tag_name, re.I):
            return True
    return False


def filter_third_party_tags(third_party_tags):
    for tag in third_party_tags:
        if is_banned(tag.name):
            logging.warning('Ignored tag %r', tag.name)
            continue

        if tag.name in config_key.get('translations', {}):
            logging.info(
                'Translated tag %r → %r',
                tag.name,
                config_key['translations'][tag.name])
            tag.name = config_key['translations'][tag.name]

        sanitized_name = sanitize_tag(tag.name)
        if sanitized_name != tag.name:
            logging.info('Sanitized tag %r → %r', tag.name, sanitized_name)
            tag.name = sanitized_name

        yield tag


def sync_tags(szuru_api, post_id, source=None):
    post = szuru_api.get_post(post_id)
    logging.info('%s/post/%d', YUME_URL, post['id'])
    logging.info(post['contentUrl'])

    new_tags = TagList()
    target_tags = TagList()
    existing_tags = TagList()
    for item in post['tags']:
        tag = Tag(item)
        target_tags.add(tag)
        existing_tags.add(tag)

    if source:
        third_party_tags = get_third_party_tags_via_urls([source])
    else:
        try:
            third_party_tags = get_third_party_tags_via_iqdb(
                post['contentUrl'])
        except iqdb.UploadTooBigIqdbError:
            third_party_tags = get_third_party_tags_via_iqdb(
                post['thumbnailUrl'])

    for third_party_tag in filter_third_party_tags(third_party_tags):
        if third_party_tag in target_tags:
            continue

        target_tags.add(third_party_tag)

        try:
            szuru_api.get_tag(third_party_tag.name)
            logging.info('Added existing tag %r', third_party_tag.name)
        except SzurubooruApiError as ex:
            if 'not found' in str(ex).lower():
                logging.warning('Added new tag %r', third_party_tag.name)
                new_tags.add(third_party_tag)
            else:
                raise

        for implication in szuru_api.collect_tag_implications(
                third_party_tag.name):
            if implication not in target_tags:
                target_tags.add(implication)
                logging.info('Added implication %r', implication.name)

    num_tags_added = len(target_tags) - len(existing_tags)
    if num_tags_added <= 0:
        logging.success('No new tags.')
        return

    if 'tagme' in target_tags:
        logging.info('Deleting tag %r', 'tagme')
        target_tags.remove('tagme')

    for new_tag in new_tags:
        logging.info('Creating new tag: %r', new_tag.name)
        if new_tag.category in ('artist', 'copyright', 'character'):
            new_tag.name = capitalize(new_tag.name)
        szuru_api.create_tag({
            'names': [new_tag.name],
            'category': config_key['categories'][new_tag.category],
        })

    logging.info('Updating post tags')
    szuru_api.update_post(post_id, {
        'tags': [tag.name for tag in target_tags],
        'version': post['version'],
    })
    logging.success('Tagged with %d tags.', num_tags_added)


class TaggingHistory:
    def __init__(self):
        self._history = {'tagged': set(), 'untagged': set(), 'unknown': set()}
        self._load()

    def mark_as_tagged(self, post_id):
        self._history['tagged'].add(post_id)
        self._save()

    def mark_as_untagged(self, post_id):
        self._history['untagged'].add(post_id)
        self._save()

    def get_processed_post_ids(self):
        return self._history['tagged'] \
            | self._history['untagged'] \
            | self._history.get('unknown', set())

    def get_tagged_post_ids(self):
        return self._history['tagged']

    def get_untagged_post_ids(self):
        return self._history['untagged']

    def _load(self):
        if os.path.exists(HISTORY_PATH):
            with open(HISTORY_PATH, 'r') as handle:
                result = json.load(handle)
                self._history = {}
                for key in ['tagged', 'untagged', 'unknown']:
                    self._history[key] = set(result.get(key, []))

    def _save(self):
        result = {}
        for key in ['tagged', 'untagged', 'unknown']:
            result[key] = sorted(list(self._history[key]))
        with open(HISTORY_PATH, 'w') as handle:
            json.dump(result, handle)


class Command:
    def __init__(self):
        self._history = TaggingHistory()
        self._szuru_api = SzurubooruApi()

    @classmethod
    def decorate_parser(cls, parent_parser):
        parser = cls._create_parser(parent_parser)
        parser.set_defaults(command=cls)
        parser.set_defaults(command=cls)

    def run(self, args):
        raise NotImplementedError()

    @staticmethod
    def _create_parser(parent_parser):
        raise NotImplementedError()


class FetchNewestCommand(Command):
    def run(self, args):
        post_id = self._get_last_post_id()
        if not post_id:
            logging.success('All posts up to date')
            return
        if post_id in self._history.get_processed_post_ids():
            logging.info('Skipping post %d - already processed', post_id)
            return
        logging.info('Getting post %d...', post_id)
        try:
            sync_tags(self._szuru_api, post_id)
            self._history.mark_as_tagged(post_id)
        except ConnectionError as ex:
            logging.error(str(ex))
            return False
        except Exception as ex:
            logging.error(str(ex))
            self._history.mark_as_untagged(post_id)
            return False
        return True

    @staticmethod
    def _create_parser(parent_parser):
        return parent_parser.add_parser(
            'newest', help='fetch tags for newest posts', aliases=['last'])

    def _get_last_post_id(self):
        latest_id = self._szuru_api.get_last_post_id()
        processed_post_ids = self._history.get_processed_post_ids()
        for post_id in range(1, latest_id + 1):
            if post_id not in processed_post_ids:
                return post_id
        return None


class FetchChosenPostCommand(Command):
    def run(self, args):
        all_succeeded = True
        for post_id in args.post_ids:
            if post_id in self._history.get_processed_post_ids() \
                    and not args.force:
                logging.info('Skipping post %d - already processed', post_id)
                continue
            logging.info('Getting post %d...', post_id)
            try:
                sync_tags(self._szuru_api, post_id, args.source)
                self._history.mark_as_tagged(post_id)
            except ConnectionError as ex:
                logging.error(str(ex))
                all_succeeded = False
            except Exception as ex:
                logging.error(str(ex))
                all_succeeded = False
                self._history.mark_as_untagged(post_id)
        return all_succeeded

    @staticmethod
    def _create_parser(parent_parser):
        parser = parent_parser.add_parser(
            'single', help='fetch tags for chosen posts', aliases=['id'])
        parser.add_argument(
            metavar='POST_ID', dest='post_ids', nargs='*', type=int,
            help=(
                'ID of the post to edit the tags for. ' +
                'If not specified, use latest unprocessed post'))
        parser.add_argument(
            '-f', '--force', action='store_true', help=(
                'Force downloading post tags, even if the post was ' +
                'processed earlier.'))
        parser.add_argument(
            '--source', help='Source URL where to get tags from.')
        return parser


def parse_args():
    parser = argparse.ArgumentParser(
        description='Pulls tags from Gelbooru to Szurubooru')
    subparsers = parser.add_subparsers(
        help='choose the command', dest='command')
    FetchNewestCommand.decorate_parser(subparsers)
    FetchChosenPostCommand.decorate_parser(subparsers)
    args = parser.parse_args()
    if not args.command:
        parser.print_help()
        return None
    return args


def main():
    args = parse_args()
    succeeded = args and args.command().run(args)
    sys.exit(0 if succeeded else 1)


if __name__ == '__main__':
    main()
