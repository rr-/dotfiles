#!/bin/python3
# Downloads images crawled by cron on the server to local directory.
# Additionally, distributes the images to specific folders, and filters out
# small images.

import re
import argparse
from os import scandir, path, makedirs, rmdir, unlink
from shutil import move
from subprocess import run
from socket import gethostname
from PIL import Image
from dotfiles import logging

logger = logging.getLogger(__name__)

LOCAL_HOST = 'tornado'
REMOTE_HOST = 'cyclone'

LOCAL_ROOT_DIR = path.expanduser('~/img/net/')
TRANSIT_ROOT_DIR = path.expanduser('~/hub/img/')
REMOTE_ROOT_DIR = path.expanduser('~/hub/img/')
SMALL_IMAGE_EXTENSIONS = ['png', 'jpg', 'jpeg']


def _parse_args():
    description = (
        'Downloads, filters and organizes into directories ' +
        'images crawled by cron job.')
    parser = argparse.ArgumentParser(description=description)
    parser.add_argument(
        '--dry', action='store_true', help='don\'t do anything')
    parser.add_argument('--min-image-width', default=300, type=int)
    parser.add_argument('--min-image-height', default=300, type=int)
    return parser.parse_args()


def _find_directories_recursive(root_dir):
    ''' Returns all sub directories in DFS order '''
    stack = [root_dir]
    result = []
    while len(stack):
        dir_path = stack.pop(0)
        result.append(dir_path)
        for entry in scandir(dir_path):
            if entry.is_dir():
                stack.insert(0, entry.path)
    while len(result):
        yield result.pop()


def _find_files(root_dir):
    return [entry.path for entry in scandir(root_dir) if entry.is_file()]


def _is_image_too_small(source_path, args):
    min_image_area = args.min_image_width * args.min_image_height
    try:
        with Image.open(source_path) as image:
            image_width, image_height = image.size
            image_area = image_width * image_height
            if image_area < min_image_area:
                return True
    except:
        pass
    return False


def main():
    args = _parse_args()
    if gethostname() != LOCAL_HOST:
        raise RuntimeError('Must be run on %s' % LOCAL_HOST)

    run([
        'rsync',
        '--progress',
        '--whole-file',
        '-a',
        '--remove-source-files',
        '%s:%s' % (REMOTE_HOST, REMOTE_ROOT_DIR),
        TRANSIT_ROOT_DIR])

    source_directories = list(_find_directories_recursive(TRANSIT_ROOT_DIR))
    for source_directory in source_directories:
        target_directory = path.join(
            LOCAL_ROOT_DIR, path.relpath(source_directory, TRANSIT_ROOT_DIR))
        target_directory = re.sub(
            r'([^\\/]*)\.2chan\.net', r'2chan/\1', target_directory)
        target_directory = re.sub(
            r'[^\\/]*\.(4chan|4cdn)\.org', '4chan', target_directory)

        makedirs(target_directory, exist_ok=True)

        source_files = list(_find_files(source_directory))
        for source_file in source_files:
            extension = path.splitext(source_file)[1].lower().strip('.')
            target_file = path.join(
                target_directory, path.basename(source_file))

            if extension in SMALL_IMAGE_EXTENSIONS \
                    and _is_image_too_small(source_file, args):
                logger.warning('%s: too small, ignoring', source_file)
                if not args.dry:
                    unlink(source_file)
                continue

            logger.info('%s: ok', source_file)
            if not args.dry:
                move(source_file, target_file)

        if not args.dry:
            run(['distribute-files', target_directory, '--fill-last', '-v'])

        try:
            rmdir(source_directory)
        except OSError:
            pass


if __name__ == '__main__':
    main()
